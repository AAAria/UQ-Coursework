---
title: "R Notebook"
output: html_notebook
---
### Task 1: PCA
```{r}
library("FactoMineR")
library("factoextra")
```

```{r}
alon.pca <- PCA(x, ncp=62,graph = FALSE)
write.csv(alon.pca$var$contrib, file='var_contr.csv')
write.csv(alon.pca$ind$contrib, file='ind_contr.csv')

```

```{r}
eig.val <- get_eigenvalue(alon.pca)

# individual variance component
plot(eig.val[,2], xlab='component', ylab='variance percent', main='Individual Variance Proportions by Each Component')

# cumulative variance proportions 
plot(eig.val[,3], xlab='component', ylab='variance percent', main='Cumulative Variance Proportions by Each Component')

```

```{r}
fviz_contrib(alon.pca, choice = "var", axes = 1, top = 10) #PC1
fviz_contrib(alon.pca, choice = "var", axes = 1:5, top = 10) #PC1-5
```

### Task 2: SVA
```{r}
gene_index = c(1:ncol(x))
sample_index = c(1:nrow(x))
p_values <- data.frame(gene = gene_index, p_value=NA)

# original p-values
for (j in gene_index){
  tumor_sample <- vector()
  normal_sample <- vector()
  for (i in sample_index){
    if (y[i] == 'Tumour'){
      tumor_sample <- c(tumor_sample, x[i,j])}
    else{normal_sample <- c(normal_sample, x[i,j])}
  }
  or_p <- t.test(tumor_sample, normal_sample, conf.level = 0.95)$p.value
  p_values$p_value[p_values$gene==j] <- or_p
}

# adjusted p-values
ad_p <- p.adjust(p_values$p_value, method='fdr')
p_values$fdr <- ad_p

# significant genes
p_values <- p_values[order(p_values$p_value),] # reorder by p-values
row.names(p_values) <- NULL # assign index to the reordered dataframe
p_values$judgement[p_values$fdr<=0.01] <- 'significant'
write.csv(p_values, file='significant_genes.csv')

# plot gene vs. p-value
sig_pval <- data.frame(p_value = subset(p_values$p_value, p_values$fdr<=0.01), selection = 'fdr')
sig_pval <- rbind(sig_pval, data.frame(p_value = subset(p_values$p_value, p_values$p_value<0.05 & p_values$fdr>0.01), selection = 't-test'))
library(ggplot2)
library(scales)
ggplot(sig_pval, aes(x=1:600, y=p_value, color=selection))  + geom_point(shape=20) + scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
              labels = trans_format("log10", math_format(10^.x))) +
stat_function(fun = function(x) 0.01*x/2000, color='black') +
xlab("gene ordered by p-value") + ylab("p-values") + ggtitle("significant gene vs. p-value")

```


# Task 5
```{r}
# train & test data set
set.seed(123)
train_index <- sample(1:nrow(x), 0.6 * nrow(x))
test_index <- setdiff(1:nrow(x), train_index)

# train set 80%
x_train <- x[train_index,]
y_train <- y[train_index]

# test set 20%
x_test <- x[test_index,] 
y_test <- y[test_index]
  
```

```{r}
# Train MDA
library(caret)
ctrl <- trainControl(method = "cv", number=10)
nnet.fit <- train(x_train, y_train, method='nnet', preProcess='pca', trControl = ctrl)
ggplot(nnet.fit)
print(nnet.fit, details=TRUE)

# predictions & confusion matrix
pred_nnet <- predict(nnet.fit, x_test)
conf_nnet <- as.matrix(confusionMatrix(pred_nnet, y_test))

# Error rates for test set
class_name <- c('Normal', 'Tumour', 'Overall')
test_error <- data.frame(class=class_name, error_rate=NA)

# class-specific error rates
for (n in 1:2){
  all = sum(conf_nnet[,n])
  success = conf_nnet[n,n]
  fail = all - success
  test_error$error_rate[test_error$class==class_name[n]] <- fail/all
}
# overall error rate
all = sum(conf_nnet)
success = sum(diag(conf_nnet))
fail = all - success
test_error$error_rate[test_error$class=='Overall'] <- fail/all
test_error

```

```{r}
# train LASSO logistic regression
library(glmnet)
cv.fit <- cv.glmnet(x_train, y_train, type.measure="class", nfolds=10, family = "binomial") # 10-fold cv
print(cv.fit)
plot(cv.fit)

# predictions, predictor variables, confusion matrix
pred_llr <- predict(cv.fit, x_test, type='class')
pred_variable <- predict(cv.fit, x_test, type='nonzero')[,1] # predictor variables
pred_coe <- predict(cv.fit, x_test, type='coefficient')[,1] # coefficients
coefficient <- vector()
for (i in pred_variable){
  coefficient <- c(coefficient, pred_coe[i+1])
}
coefficient <- data.frame(coefficient)
coefficient
conf_llr <- as.matrix(confusionMatrix(as.factor(pred_llr), y_test)) # confusion matrix

# Error rates for test set
class_name <- c('Normal', 'Tumour', 'Overall')
test_error <- data.frame(class=class_name, error_rate=NA)

# class-specific error rates
for (n in 1:2){
  all = sum(conf_llr[,n])
  success = conf_llr[n,n]
  fail = all - success
  test_error$error_rate[test_error$class==class_name[n]] <- fail/all
}
# overall error rate
all = sum(conf_llr)
success = sum(diag(conf_llr))
fail = all - success
test_error$error_rate[test_error$class=='Overall'] <- fail/all
test_error

```




